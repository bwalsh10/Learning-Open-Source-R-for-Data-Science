---
title: "CTT_eval_function"
output: github_document
---

```{r}
#libraries specified under "imports" for CTT_eval Package#
library(psych)
library(tidyverse)
library(knitr)
```

```{r}

#ANNOTATED PRIMARY FUNCTION FOR "CTT_eval" PACKAGE#
ctt_eval <- function(data) {
  if (!is.data.frame(data)) {
    stop("The input data should be a data frame.")
  }
  
  # Compute Cronbach's Alpha with psych::alpha
  alpha_result <- psych::alpha(data)
  
  # Extract Cronbach's Alpha value
  alpha_value <- alpha_result$total$raw_alpha
  
  # Extract item-total correlations (item discrimination)
  item_total_corr <- alpha_result$item.stats$r.drop
  
  # Extract alpha if item deleted
  alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
  
  # Compute descriptive statistics: mean, SD, skewness, kurtosis
  desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
  
  # Round descriptive statistics to two decimal points
  desc_stats <- desc_stats %>%
    mutate(
      mean = round(mean, 2),
      sd = round(sd, 2),
      skew = round(skew, 2),
      kurtosis = round(kurtosis, 2)
    )
  
  # Compute range of scores for each item
  item_ranges <- apply(data, 2, function(x) paste0("[", min(x), ", ", max(x), "]"))
  
  # Add item discrimination and alpha-if-item-deleted to descriptive stats
  desc_stats$item_discrimination <- round(item_total_corr, 2)
  desc_stats$alpha_if_deleted <- alpha_if_deleted
  
  # Add descriptions for item discrimination quality
  desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
    if (corr > 0.80) {
      return("Strong correlation")
    } else if (corr > 0.60) {
      return("Moderate correlation")
    } else if (corr > 0.40) {
      return("Weak correlation")
    } else {
      return("Item may need revision")
    }
  })
  
  # Add range of scores to descriptive stats
  desc_stats$item_range <- item_ranges
  
  # Create a clean output table combining all statistics and descriptions
  clean_table <- desc_stats %>%
    mutate(Item = rownames(desc_stats)) %>%
    select(Item, mean, sd, skew, kurtosis, item_range, item_discrimination, alpha_if_deleted, item_quality)
  
  # Compute total scale statistics
  total_scores <- rowSums(data)
  total_mean <- round(mean(total_scores), 2)
  total_sd <- round(sd(total_scores), 2)
  total_range <- paste0("[", min(total_scores), ", ", max(total_scores), "]")
  
  reliability_quality <- cut(alpha_value,
                             breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
                             labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
                             right = FALSE)
  
  # Create a separate table for total scale statistics
  scale_table <- tibble(
    Statistic = c("Mean", "SD", "Range", "Alpha", "Descriptor"),
    Value = c(total_mean, total_sd, total_range, round(alpha_value, 2), as.character(reliability_quality))
  )
  
  # Print the tables using knitr::kable for clean output
  print(knitr::kable(clean_table,
                     format = "markdown",
                     caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted and Range of Scores"))
  
  print(knitr::kable(scale_table,
                     format = "markdown",
                     caption = "Total Scale Statistics Table"))
  
  return(list(
    alpha = round(alpha_value, 2),
    alpha_quality = reliability_quality,
    descriptive_stats_table = clean_table,
    scale_statistics_table = scale_table
  ))
}

```

```{r}
#TESTING ctt_eval function using simulated data (100 participants completing a 10-item self-report scale)
data <-read_csv("sim_data.csv")

ctt_results <- ctt_eval(data)
```

