return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_discrimination, alpha_if_deleted, item_quality)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted"))
# Return Cronbach's Alpha and quality descriptions as well
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table
))
}
data <-read_csv("sim_data.csv")
ctt_results <- ctt_eval(data)
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Compute total score statistics
total_scores <- rowSums(data)
total_mean <- round(mean(total_scores), 2)
total_sd <- round(sd(total_scores), 2)
# Append scale-level statistics as a new row
scale_row <- tibble(
Item = "Scale Statistics",
mean = total_mean,
sd = total_sd,
skew = "--",
kurtosis = "--",
item_discrimination = "--",
alpha_if_deleted = round(alpha_value, 2),
item_quality = cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
)
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_discrimination, alpha_if_deleted, item_quality) %>%
bind_rows(scale_row)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Scale-Level Statistics"))
return(list(
alpha = round(alpha_value, 2),
descriptive_stats_table = clean_table,
total_mean = total_mean,
total_sd = total_sd
))
}
ctt_results <- ctt_eval(data)
#libraries specified under "imports" for CTT_eval Package#
library(psych)
library(tidyverse)
library(knitr)
#TESTING ctt_eval function using simulated data (100 participants completing a 10-item self-report scale)
data <-read_csv("sim_data.csv")
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Compute total score statistics
total_scores <- rowSums(data)
total_mean <- round(mean(total_scores), 2)
total_sd <- round(sd(total_scores), 2)
# Append scale-level statistics as a new row
scale_row <- tibble(
Item = "Scale Statistics",
mean = total_mean,
sd = total_sd,
skew = "--",
kurtosis = "--",
item_discrimination = "--",
alpha_if_deleted = round(alpha_value, 2),
item_quality = cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
)
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_discrimination, alpha_if_deleted, item_quality) %>%
bind_rows(scale_row)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Scale-Level Statistics"))
return(list(
alpha = round(alpha_value, 2),
descriptive_stats_table = clean_table,
total_mean = total_mean,
total_sd = total_sd
))
}
ctt_results <- ctt_eval(data)
#libraries specified under "imports" for CTT_eval Package#
library(psych)
library(tidyverse)
library(knitr)
#ANNOTATED PRIMARY FUNCTION FOR CTT EVAL PACKAGE#
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_discrimination, alpha_if_deleted, item_quality)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted"))
# Return Cronbach's Alpha and quality descriptions as well
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table
))
}
#TESTING ctt_eval function using simulated data (100 participants completing a 10-item self-report scale)
data <-read_csv("sim_data.csv")
ctt_results <- ctt_eval(data)
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Compute range of scores for each item
item_ranges <- apply(data, 2, function(x) paste0("[", min(x), ", ", max(x), "]"))
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Add range of scores to descriptive stats
desc_stats$item_range <- item_ranges
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_range, item_discrimination, alpha_if_deleted, item_quality)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted and Range of Scores"))
# Return Cronbach's Alpha and quality descriptions as well
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table
))
}
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Compute range of scores for each item
item_ranges <- apply(data, 2, function(x) paste0("[", min(x), ", ", max(x), "]"))
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Add range of scores to descriptive stats
desc_stats$item_range <- item_ranges
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_range, item_discrimination, alpha_if_deleted, item_quality)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted and Range of Scores"))
# Return Cronbach's Alpha and quality descriptions as well
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table
))
}
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Compute range of scores for each item
item_ranges <- apply(data, 2, function(x) paste0("[", min(x), ", ", max(x), "]"))
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Add range of scores to descriptive stats
desc_stats$item_range <- item_ranges
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_range, item_discrimination, alpha_if_deleted, item_quality)
# Print the table using knitr::kable for a clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted and Range of Scores"))
# Return Cronbach's Alpha and quality descriptions as well
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table
))
}
ctt_results <- ctt_eval(data)
ctt_eval <- function(data) {
if (!is.data.frame(data)) {
stop("The input data should be a data frame.")
}
# Compute Cronbach's Alpha with psych::alpha
alpha_result <- psych::alpha(data)
# Extract Cronbach's Alpha value
alpha_value <- alpha_result$total$raw_alpha
# Extract item-total correlations (item discrimination)
item_total_corr <- alpha_result$item.stats$r.drop
# Extract alpha if item deleted
alpha_if_deleted <- round(alpha_result$alpha.drop[, "raw_alpha"], 2)
# Compute descriptive statistics: mean, SD, skewness, kurtosis
desc_stats <- psych::describe(data)[, c("mean", "sd", "skew", "kurtosis")]
# Round descriptive statistics to two decimal points
desc_stats <- desc_stats %>%
mutate(
mean = round(mean, 2),
sd = round(sd, 2),
skew = round(skew, 2),
kurtosis = round(kurtosis, 2)
)
# Compute range of scores for each item
item_ranges <- apply(data, 2, function(x) paste0("[", min(x), ", ", max(x), "]"))
# Add item discrimination and alpha-if-item-deleted to descriptive stats
desc_stats$item_discrimination <- round(item_total_corr, 2)
desc_stats$alpha_if_deleted <- alpha_if_deleted
# Add descriptions for item discrimination quality
desc_stats$item_quality <- sapply(item_total_corr, function(corr) {
if (corr > 0.80) {
return("Strong correlation")
} else if (corr > 0.60) {
return("Moderate correlation")
} else if (corr > 0.40) {
return("Weak correlation")
} else {
return("Item may need revision")
}
})
# Add range of scores to descriptive stats
desc_stats$item_range <- item_ranges
# Create a clean output table combining all statistics and descriptions
clean_table <- desc_stats %>%
mutate(Item = rownames(desc_stats)) %>%
select(Item, mean, sd, skew, kurtosis, item_range, item_discrimination, alpha_if_deleted, item_quality)
# Compute total scale statistics
total_scores <- rowSums(data)
total_mean <- round(mean(total_scores), 2)
total_sd <- round(sd(total_scores), 2)
total_range <- paste0("[", min(total_scores), ", ", max(total_scores), "]")
reliability_quality <- cut(alpha_value,
breaks = c(-Inf, 0.7, 0.8, 0.9, Inf),
labels = c("Poor reliability", "Acceptable reliability", "Good reliability", "Excellent reliability"),
right = FALSE)
# Create a separate table for total scale statistics
scale_table <- tibble(
Statistic = c("Mean", "SD", "Range", "Alpha", "Descriptor"),
Value = c(total_mean, total_sd, total_range, round(alpha_value, 2), as.character(reliability_quality))
)
# Print the tables using knitr::kable for clean output
print(knitr::kable(clean_table,
format = "markdown",
caption = "Descriptive Statistics Table with Alpha-if-Item-Deleted and Range of Scores"))
print(knitr::kable(scale_table,
format = "markdown",
caption = "Total Scale Statistics Table"))
return(list(
alpha = round(alpha_value, 2),
alpha_quality = reliability_quality,
descriptive_stats_table = clean_table,
scale_statistics_table = scale_table
))
}
ctt_results <- ctt_eval(data)
library(CTTeval)
#Step 3: print the results
print(ctt_results)
#Step 3: print the results
ctt_results
#Step 3: print the results for each table
print(ctt_results$descriptive_stats_table)
#Step 3: print the results for each table
print(ctt_results$descriptive_stats_table)
#Step 2: apply the "ctt_eval" function to your data. The results will give you two seperate tables. One table for item-level statistics and one table for scale-level statistics. All indices can be used to evaluate the quality of your scale from a Classical Test Theory Perspective. Descriptive labels are applied to certain statistics to aid interpretation.
ctt_results <- ctt_eval(data)
#Step 3: print the results for each table
print(ctt_results$descriptive_stats_table)
